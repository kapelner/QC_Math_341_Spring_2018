\documentclass[12pt]{article}

\include{preamble}

\newtoggle{professormode}
\toggletrue{professormode} %STUDENTS: DELETE or COMMENT this line



\title{MATH 341 / 650.3 Spring 2018 Homework \#3}

\author{Professor Adam Kapelner} %STUDENTS: write your name here

\iftoggle{professormode}{
\date{Due Friday 5PM, March 16, 2018 under the door of KY604 \\ \vspace{0.5cm} \small (this document last updated \today ~at \currenttime)}
}

\renewcommand{\abstractname}{Instructions and Philosophy}

\begin{document}
\maketitle

\iftoggle{professormode}{
\begin{abstract}
The path to success in this class is to do many problems. Unlike other courses, exclusively doing reading(s) will not help. Coming to lecture is akin to watching workout videos; thinking about and solving problems on your own is the actual ``working out.''  Feel free to \qu{work out} with others; \textbf{I want you to work on this in groups.}

Reading is still \textit{required}. For this homework set, review the beta-binomial conjugate model, Bayesian Hypothesis Testing, Bayes Factors, Empirical Bayes, the beta-binomial distribution (and also, posterior predictive distributions), uninformative priors and read the relevant sections of McGrayne. 

The problems below are color coded: \ingreen{green} problems are considered \textit{easy} and marked \qu{[easy]}; \inorange{yellow} problems are considered \textit{intermediate} and marked \qu{[harder]}, \inred{red} problems are considered \textit{difficult} and marked \qu{[difficult]} and \inpurple{purple} problems are extra credit. The \textit{easy} problems are intended to be ``giveaways'' if you went to class. Do as much as you can of the others; I expect you to at least attempt the \textit{difficult} problems. 

Problems marked \qu{[MA]} are for the masters students only (those enrolled in the 650.3 course). For those in 341, doing these questions will count as extra credit.

This homework is worth 100 points but the point distribution will not be determined until after the due date. See syllabus for the policy on late homework.

Up to 10 points are given as a bonus if the homework is typed using \LaTeX. Links to instaling \LaTeX~and program for compiling \LaTeX~is found on the syllabus. You are encouraged to use \url{overleaf.com}. If you are handing in homework this way, read the comments in the code; there are two lines to comment out and you should replace my name with yours and write your section. The easiest way to use overleaf is to copy the raw text from hwxx.tex and preamble.tex into two new overleaf tex files with the same name. If you are asked to make drawings, you can take a picture of your handwritten drawing and insert them as figures or leave space using the \qu{$\backslash$vspace} command and draw them in after printing or attach them stapled.

The document is available with spaces for you to write your answers. If not using \LaTeX, print this document and write in your answers. I do not accept homeworks which are \textit{not} on this printout. Keep this first page printed for your records.

\end{abstract}

\thispagestyle{empty}
\vspace{1cm}
NAME: \line(1,0){380}
\clearpage
}


\problem{These are questions about McGrayne's book, chapters 8-10.}

\begin{enumerate}

\easysubproblem{When was experimentation introduced to medical science and who introduced it? Are you surprised that it was this recent?}\spc{1}

\easysubproblem{Sir Ronald A. Fisher, the founder of modern experiments, did not believe cigarettes caused lung cancer. What were his two hypotheses for the cause of lung cancer?}\spc{2}

\easysubproblem{Who invented, and what are Bayes Factors? (p116)}\spc{2}

\easysubproblem{Trick question: who convinced Cornfield to stop smoking?}\spc{2}

\easysubproblem{Why were frequentists at a loss to estimate the probability of a nuclear bomb being detonated by accident?}\spc{2}

\easysubproblem{What is \href{https://en.wikipedia.org/wiki/Cromwell\%27s_rule}{Cromwell's Rule}? And, when applying this principle to a Bayesian model what would it imply? (See the Wikipedia link and p123).}\spc{2}

\easysubproblem{Did Bayesian Statistics prevent nuclear accidents? Discuss.}\spc{5}

\easysubproblem{What is the main reason why there are so many variations of Bayesian interpretation? (p129)}\spc{4}

\easysubproblem{What is a large practical drawback of Bayesian inference? (See mid-end of chapter 8).}\spc{9}

\end{enumerate}

\problem{We will again be looking at the beta-prior, binomial-likelihood Bayesian model and practicing hypothesis testing.}


\begin{enumerate}

\intermediatesubproblem{[Also on HW\#2] Design a prior where you believe $\expe{\theta} = 0.5$ and you feel as if your belief represents information contained in five coin flips.}\spc{3}

\intermediatesubproblem{You flip the same coin 100 times and you observe 39 heads. Test the hypothesis that this coin is fair given prior information from (a). Use the credible region method. Make sure you say whether you retain or reject the null and justify why.}\spc{6}

\intermediatesubproblem{Test the hypothesis that this coin has a bias towards Heads (not tails) given prior information from (a) and the data from (c). Calculate the Bayesian $p$-val for the test to determine if you should retain or reject $H_0$.}\spc{6}

\easysubproblem{Let's say you wanted to test whether the coin is fair but you are indifferent to any $\theta$ which is different from 0.5 by a margin of 0.1. Write out the hypotheses for this test.}\spc{3}

\intermediatesubproblem{Test the hypotheses from (h) given prior information from (a) and the data from (c). Make sure you say whether you retain or reject the null and justify why.}\spc{10}


\intermediatesubproblem{Calculate the Bayesian $p$-val for the test in (i).}\spc{4}

\intermediatesubproblem{Given the tested hypotheses from (i) and data from (c), write the formula for the Bayes factor and then write the integral expression. Do not solve.}\spc{4}


\intermediatesubproblem{[MA] Calculate the Bayes Factor numerically by solving the integral expression in (k). Interpret your value of $K$ (or $B$) according to \href{https://en.wikipedia.org/wiki/Bayes_factor}{wikipedia page about Bayes Factors}.}\spc{11}

\easysubproblem{Assume again the prior information from (a). What is the shrinkage proportion $\rho$ for this prior when estimating $\theta$ via $\thetahatmmse$?.}\spc{2}

\hardsubproblem{Prove that $\thetahatmmse$ is a biased estimator (i.e. its expectation is \textit{not} $\theta$).}\spc{5}

\easysubproblem{Prove that $\displaystyle \limitn \rho = 0$ and therefore this bias $\rightarrow 0$ as your dataset gets larger.}\spc{4}

\hardsubproblem{[MA] Why on Earth should anyone use shrinkage estimators if they're biased? Google it. Discuss.}\spc{4}

\end{enumerate}



\problem{Some quick question on mixture distributions.}

\begin{enumerate}

\easysubproblem{If $X$ is independent to $W$ and $X$ is independent to $Z$ and $X$ is independent to $U$, can you write $\cprob{X}{U,V,W,Y,Z}$ more compactly? Do so below.}\spc{1}

\easysubproblem{Let $X$ be $\normnot{0}{1^2}$ 1/3 of the time and $\exponential{3}$ 2/3 of the time. What is its pdf?}\spc{2}


\hardsubproblem{Let's say $X~|~\beta \sim \betanot{1}{\beta}$ where $\beta~|~\lambda \sim \exponential{\lambda}$. Write an integral expression which when solved, finds the compound / marginal density of $X$. DO NOT solve.}\spc{6}

\hardsubproblem{[MA] Let's say $X~|~\theta,~\sigsq \sim \normnot{\theta}{\sigsq}$ where $\theta~|~\mu_0,~\tausq \sim \normnot{\mu_0}{\tausq}$. Write an integral expression which when solved, finds the compound / marginal density of $X$. DO NOT solve.}\spc{4}

\end{enumerate}





\problem{These are questions about other vague priors: improper priors and Jeffreys priors.}

\begin{enumerate}

\easysubproblem{What is an improper prior?}\spc{2}

\easysubproblem{Is $\theta \sim \betanot{100}{0}$ improper? Yes / no and provide a proof.}\spc{4}

\easysubproblem{When are improper priors \qu{legal}?}\spc{4}

\easysubproblem{When are improper priors \qu{illegal}?}\spc{4}

\hardsubproblem{What does $I(\theta)$ tell you about the random variable with respect to its parameter $\theta$?}\spc{5}

\intermediatesubproblem{If I compute a posterior on the $\theta$ scale and then measure the parameter on another scale, will I (generally) get the same posterior probability? Yes/no explain.}\spc{4}


\easysubproblem{What is the Jeffrey's prior for $\theta$ under the binomial likelihood? Your answer must be a distribution.}\spc{4}

\hardsubproblem{What is the Jeffrey's prior for $\theta = t^{-1}(r) = \frac{e^r}{1 + e^r}$ (i.e. the log-odds reparameterization) under the binomial likelihood?}\spc{6}


\hardsubproblem{Explain the advantage of Jeffrey's prior.}\spc{12}

\hardsubproblem{[MA] Prove Jeffrey's invariance principle i.e. prove that the Jeffrey's prior makes your prior probability immune to transformations. Use the second proof from class.}\spc{12}

\end{enumerate}


\problem{This question is about \qu{batting averages} in baseball.

\begin{figure}[htp]
\centering
\includegraphics[width=3.8in]{baseball.jpg}
\end{figure}

\noindent Every hitter's \emph{sample} batting average (BA) is defined as:

\beqn
BA := \frac{\text{sample \# of hits}}{\text{sample \# of at bats}}
\eeqn

In this problem we care about estimating a hitter's \emph{true} batting average which we call $\theta$. Each player has a different $\theta$ but we focus in this problem on one specific player. In order to estimate the player's true batting average, we make use of the sample batting average as defined above (with Bayesian modifications, of course). 

We assume that each at bat (for any player) are conditionally $\iid$ based on the players' true batting average, $\theta$. So if a player has $n$ at bats, then each successful hit in each at bat can be modeled via $X_1~|~\theta, ~X_2~|~\theta, \ldots, ~X_n~|~\theta \iid \bernoulli{\theta}$ i.e. the standard assumption.}

\begin{enumerate}

\easysubproblem{Looking at the entire dataset for 6,061 batters who had 100 or more at bats, I fit a beta function to the sample batting averages and estimated $\alpha = 42.3$ and $\beta = 127.7$ (which we called \qu{empirical Bayes} estimates in class). Consider building a prior from this estimate as $\theta \sim \betanot{42.3}{127.7}$ Would a prior based on these hyperparameter estimates be \qu{objective}? Yes / No. Why?}\spc{1}

\easysubproblem{Using prior data to build the prior is called...}\spc{0}

\easysubproblem{Is the prior from (a) considered a \qu{conjugate prior}? Yes / No.}\spc{0.5}

\easysubproblem{Using the prior from (a), find the $\thetahatmmse$.}\spc{0.5}

\hardsubproblem{We now observe four at bats for a new player and there were no hits. Write an exact expression for the batter getting 14 or more hits on the next 20 at bats. You can leave your answer in terms of the beta function. Do not compute explicitly.} \spc{5}

\end{enumerate}

\end{document}

%\problem{This problem is concerned with the \qu{Epistemic View} of probability --- this is the view that probabilities are inherently living inside the minds of human beings who are forced to grapple with uncertainty as they see it. One definition is the \textbf{Logical} definition which means that given the same information, everyone would come to the same conclusion. The logical definition requires the principle of indifference.}
%
%\begin{enumerate}
%
%\easysubproblem{
%We will now go about showing that the principle of indifference has a tenuous foundation thereby rendering the logical theory of probability inadequate. We begin with demonstrating a paradox in the logical definition for a discrete set of $\theta_0$. \\
%
%Imagine you have a library with thousands of books but all are either red, green, yellow or purple but you don't know the proportions of the books' colors. Imagine you are blindfolded and select a random book and you are only interested if it's \textit{red} or \textit{not red}. According to the principle of indifference, what is your prior probability that the book is red? Remember, $|\Theta_0|  = 2$ here.}\spc{2}
%
%\easysubproblem{Imagine you are blindfolded and select a random book and you are interested if it's red, green, yellow or purple. According to the principle of indifference, what is your prior probability that the book is red? Remember, $|\Theta_0|  = 4$ here.}\spc{1}
%
%
%\intermediatesubproblem{Why do (a) and (b) constitute a paradox? Does this limit the application of the principle of indifference?}\spc{4}
%
%\end{enumerate}

%\problem{We will now have lots of examples finding kernels from common distributions. Some of these questions are silly, but they will force you to think hard about what the kernel is under different situations. And... they're fun!}
%
%\begin{enumerate}
%
%\easysubproblem{What is the kernel of $X~|~\theta,~n \sim \binomial{n}{\theta}$?}\spc{3}
%
%\hardsubproblem{What is the kernel of $X, n~|~\theta \sim \binomial{n}{\theta}$? Be careful...}\spc{3}
%
%\easysubproblem{What is the kernel of $X~|~\theta \sim \poisson{\theta}$?}\spc{3}
%
%\hardsubproblem{What is the kernel of $\theta~|~X \sim \poisson{\theta}$? Be careful...}\spc{3}
%
%\easysubproblem{What is the kernel of $X~|~\alpha,~\beta \sim \stdbetanot$?}\spc{4}
%
%\easysubproblem{What is the kernel of $X~|~\theta \sim \exponential{\theta}$?}\spc{4}
%
%\easysubproblem{What is the kernel of $X~|~\theta,~\sigsq \sim \normnot{\theta}{\sigsq}$?}\spc{4}
%
%\hardsubproblem{What is the kernel of $\theta,~\sigsq~|~X \sim \normnot{\theta}{\sigsq}$? Be careful...}\spc{4}
%
%\intermediatesubproblem{[MA] What is the kernel of 
%
%\beqn
%X~|~N,~\theta,~n \sim \hypergeometric{N}{\theta}{n} := {{{ \theta \choose x} {{N-\theta} \choose {n-x}}}\over {N \choose n}}
%\eeqn
%
%where $N$ is the number of total balls in the bag, $\theta$ is the number of success balls in the bag and $n$ is the number drawn out of the bag?}\spc{9}
%
%%\hardsubproblem{[MA] If $X~|~\theta,~\sigsq \sim \normnot{\theta}{\sigsq}$ and $\theta~|~\mu_0,~\tausq \sim \normnot{\mu_0}{\tausq}$, what is the kernel of $\theta~|~X,~\sigsq,~\mu_0,~\tausq$?}\spc{6}
%
%\end{enumerate}


